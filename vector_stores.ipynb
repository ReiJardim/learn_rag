{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# VectorStores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40fddf28",
   "metadata": {},
   "source": [
    "Uma das maneiras mais comuns de armazenar e buscar dados não estruturados é realizando o embedding e armazenando os vetores resultantes e, em seguida, na hora da consulta, realizar o embedding da consulta e recuperar os vetores 'mais semelhantes'. Uma VectorStore faz o armazenamento dos vetores e a realização da busca de vetores para você"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75b6dcb5",
   "metadata": {},
   "source": [
    "## Chroma VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06928c56",
   "metadata": {},
   "source": [
    "### Document Laoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bafa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = 'arquivos/TSP_CMC_54360.pdf'\n",
    "loader = PyPDFLoader(caminho)\n",
    "paginas = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f9f485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paginas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d952ce83",
   "metadata": {},
   "source": [
    "### Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664d424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)\n",
    "len(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68ecfd35",
   "metadata": {},
   "source": [
    "### Criando a VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8a4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e345763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9af6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "diretorio = 'arquivos/chroma_vectorstore'\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38518b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b31a7e",
   "metadata": {},
   "source": [
    "### Importando vectorstore do disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d712600",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = 'arquivos/chroma_vectorstore'\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07972f66",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2778ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'O que é o Hugging Face?'\n",
    "\n",
    "docs = vectorstore.similarity_search(pergunta, k=5)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbc37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cussion information for LLM preparation, drawing upon the lavita/ChatDoctor-HealthCareMagic-\n",
      "100k dataset on Hugging Face as a source of perspective point. Here, we dig into the thinking behind\n",
      "apparently basic strategies and their effect on the adequacy of the last chatbot model.\n",
      "Our underlying step includes fragmenting the crude dataset into individual discussion strings.\n",
      "This is usually accomplished by recognizing newline characters or other delimiters that differ in one\n",
      "====== {'page': 6, 'source': 'arquivos/TSP_CMC_54360.pdf'}\n",
      "\n",
      "\n",
      "cussion information for LLM preparation, drawing upon the lavita/ChatDoctor-HealthCareMagic-\n",
      "100k dataset on Hugging Face as a source of perspective point. Here, we dig into the thinking behind\n",
      "apparently basic strategies and their effect on the adequacy of the last chatbot model.\n",
      "Our underlying step includes fragmenting the crude dataset into individual discussion strings.\n",
      "This is usually accomplished by recognizing newline characters or other delimiters that differ in one\n",
      "====== {'page': 6, 'source': 'arquivos/TSP_CMC_54360.pdf'}\n",
      "\n",
      "\n",
      "4 Experiment\n",
      "Our examination investigates the capability of consolidating Boundary Efficient Fine-Tuning\n",
      "(PEFT) strategies and quantization to make an asset-efficient and exact medical care chatbot inside the\n",
      "limits of a free Google Colab environment. We further explore the utilization of Retrieval-Augmented\n",
      "Generation (RAG) with LangChain to upgrade the chatbot’s capacity to address client inquiries by\n",
      "leveraging an outside knowledge base.\n",
      "====== {'page': 11, 'source': 'arquivos/TSP_CMC_54360.pdf'}\n",
      "\n",
      "\n",
      "4 Experiment\n",
      "Our examination investigates the capability of consolidating Boundary Efficient Fine-Tuning\n",
      "(PEFT) strategies and quantization to make an asset-efficient and exact medical care chatbot inside the\n",
      "limits of a free Google Colab environment. We further explore the utilization of Retrieval-Augmented\n",
      "Generation (RAG) with LangChain to upgrade the chatbot’s capacity to address client inquiries by\n",
      "leveraging an outside knowledge base.\n",
      "====== {'page': 11, 'source': 'arquivos/TSP_CMC_54360.pdf'}\n",
      "\n",
      "\n",
      "the test set. Implemented on the National Economics University’s official admission page on the Face-\n",
      "book platform, the chatbot showcases the potential of AI technology to streamline communication\n",
      "processes. This exploration offers point-by-point rules on building a simulated intelligence chatbot\n",
      "without any preparation, joined by methods that can be applied across various languages and settings.\n",
      "This study [5] presents the development of a university enquiry chatbot using the Rasa framework,\n",
      "====== {'page': 3, 'source': 'arquivos/TSP_CMC_54360.pdf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'====== {doc.metadata}\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e18647fc",
   "metadata": {},
   "source": [
    "## FAISS VectorStore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d27ce6a",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/vectorstores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07534776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d5ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(caminho)\n",
    "paginas = loader.load()\n",
    "\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19faf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edef8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479f1fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'O que é o Hugging Face?'\n",
    "\n",
    "docs = vectorstore.similarity_search(pergunta, k=5)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f050009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cussion information for LLM preparation, drawing upon the lavita/ChatDoctor-HealthCareMagic-\n",
      "100k dataset on Hugging Face as a source of perspective point. Here, we dig into the thinking behind\n",
      "apparently basic strategies and their effect on the adequacy of the last chatbot model.\n",
      "Our underlying step includes fragmenting the crude dataset into individual discussion strings.\n",
      "This is usually accomplished by recognizing newline characters or other delimiters that differ in one\n",
      "====== {'source': 'arquivos/TSP_CMC_54360.pdf', 'page': 6}\n",
      "\n",
      "\n",
      "4 Experiment\n",
      "Our examination investigates the capability of consolidating Boundary Efficient Fine-Tuning\n",
      "(PEFT) strategies and quantization to make an asset-efficient and exact medical care chatbot inside the\n",
      "limits of a free Google Colab environment. We further explore the utilization of Retrieval-Augmented\n",
      "Generation (RAG) with LangChain to upgrade the chatbot’s capacity to address client inquiries by\n",
      "leveraging an outside knowledge base.\n",
      "====== {'source': 'arquivos/TSP_CMC_54360.pdf', 'page': 11}\n",
      "\n",
      "\n",
      "the test set. Implemented on the National Economics University’s official admission page on the Face-\n",
      "book platform, the chatbot showcases the potential of AI technology to streamline communication\n",
      "processes. This exploration offers point-by-point rules on building a simulated intelligence chatbot\n",
      "without any preparation, joined by methods that can be applied across various languages and settings.\n",
      "This study [5] presents the development of a university enquiry chatbot using the Rasa framework,\n",
      "====== {'source': 'arquivos/TSP_CMC_54360.pdf', 'page': 3}\n",
      "\n",
      "\n",
      "Biomimetic Intell. Robot., vol. 4, no. 1, pp. 100146, 2024. doi:10.1016/j.birob.2024.100146.\n",
      "====== {'source': 'arquivos/TSP_CMC_54360.pdf', 'page': 19}\n",
      "\n",
      "\n",
      "construct space-explicit skills. While pre-prepared LLMs like Tiny Llama 1.1B Visit from Hugging\n",
      "Face offer extraordinary language understanding abilities, they could battle with medical services\n",
      "explicit wording, subtleties, and excellent client inquiries. Tweaking overcomes this issue by giving\n",
      "further preparation on an engaged dataset custom-fitted to the medical services space. This dataset\n",
      "is pivotal in moulding the LLM’s capacity to understand medical services-related ideas and precisely\n",
      "====== {'source': 'arquivos/TSP_CMC_54360.pdf', 'page': 7}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'====== {doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54a897",
   "metadata": {},
   "source": [
    "### Salvando bd FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "422c14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local('arquivos/faiss_bd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b105d5",
   "metadata": {},
   "source": [
    "### Importando bd FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e66dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    'arquivos/faiss_bd',\n",
    "    embeddings=embeddings_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
