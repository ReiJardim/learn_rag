{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharachterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 0\n",
    "\n",
    "char_split = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "texto = ''.join(f'{string.ascii_lowercase}' for _ in range(5))\n",
    "print(texto)\n",
    "print(len(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = char_split.split_text(texto)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwx',\n",
       " 'yzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuv',\n",
       " 'wxyzabcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 141, which is longer than the specified 50\n",
      "Created a chunk of size 114, which is longer than the specified 50\n",
      "Created a chunk of size 165, which is longer than the specified 50\n",
      "Created a chunk of size 196, which is longer than the specified 50\n"
     ]
    }
   ],
   "source": [
    "texto = '''\n",
    "Os LLMs enfrentam uma série de desafios atualmente, como os seguintes:\n",
    "\n",
    "Fornecer informações falsas quando não possuem uma resposta adequada.\n",
    "Oferecer informações desatualizadas ou genéricas quando os usuários solicitam respostas específicas e atualizadas.\n",
    "Gerar respostas baseadas em fontes não confiáveis.\n",
    "Criar respostas imprecisas devido à confusão terminológica, quando diferentes fontes de treinamento utilizam a mesma terminologia para descrever conceitos distintos.\n",
    "Podemos entender o grande modelo de linguagem (LLM) como um funcionário recém-contratado que opta por ignorar as notícias atuais, mas mesmo assim responde a todas as perguntas com total convicção. Contudo, essa abordagem pode impactar negativamente a confiança dos usuários, o que não é desejável para seus chatbots!\n",
    "'''\n",
    "\n",
    "chunk_size = 50\n",
    "chunk_overlap = 10\n",
    "\n",
    "char_split = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator='.'\n",
    ")\n",
    "\n",
    "splits = char_split.split_text(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Os LLMs enfrentam uma série de desafios atualmente, como os seguintes:\\n\\nFornecer informações falsas quando não possuem uma resposta adequada',\n",
       " 'Oferecer informações desatualizadas ou genéricas quando os usuários solicitam respostas específicas e atualizadas',\n",
       " 'Gerar respostas baseadas em fontes não confiáveis',\n",
       " 'Criar respostas imprecisas devido à confusão terminológica, quando diferentes fontes de treinamento utilizam a mesma terminologia para descrever conceitos distintos',\n",
       " 'Podemos entender o grande modelo de linguagem (LLM) como um funcionário recém-contratado que opta por ignorar as notícias atuais, mas mesmo assim responde a todas as perguntas com total convicção',\n",
       " 'Contudo, essa abordagem pode impactar negativamente a confiança dos usuários, o que não é desejável para seus chatbots!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = '''\n",
    "Os LLMs enfrentam uma série de desafios atualmente, como os seguintes:\n",
    "\n",
    "Fornecer informações falsas quando não possuem uma resposta adequada.\n",
    "Oferecer informações desatualizadas ou genéricas quando os usuários solicitam respostas específicas e atualizadas.\n",
    "Gerar respostas baseadas em fontes não confiáveis.\n",
    "Criar respostas imprecisas devido à confusão terminológica, quando diferentes fontes de treinamento utilizam a mesma terminologia para descrever conceitos distintos.\n",
    "Podemos entender o grande modelo de linguagem (LLM) como um funcionário recém-contratado que opta por ignorar as notícias atuais, mas mesmo assim responde a todas as perguntas com total convicção. Contudo, essa abordagem pode impactar negativamente a confiança dos usuários, o que não é desejável para seus chatbots!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100\n",
    "chunk_overlap = 20  \n",
    "\n",
    "\n",
    "char_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=['\\n\\n', '\\n', '.', '?', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Os LLMs enfrentam uma série de desafios atualmente, como os seguintes:',\n",
       " 'Fornecer informações falsas quando não possuem uma resposta adequada.',\n",
       " 'Oferecer informações desatualizadas ou genéricas quando os usuários solicitam respostas específicas',\n",
       " 'específicas e atualizadas',\n",
       " '.',\n",
       " 'Gerar respostas baseadas em fontes não confiáveis.',\n",
       " 'Criar respostas imprecisas devido à confusão terminológica, quando diferentes fontes de treinamento',\n",
       " 'de treinamento utilizam a mesma terminologia para descrever conceitos distintos',\n",
       " '.',\n",
       " 'Podemos entender o grande modelo de linguagem (LLM) como um funcionário recém-contratado que opta',\n",
       " 'que opta por ignorar as notícias atuais, mas mesmo assim responde a todas as perguntas com total',\n",
       " 'perguntas com total convicção',\n",
       " '. Contudo, essa abordagem pode impactar negativamente a confiança dos usuários, o que não é',\n",
       " 'o que não é desejável para seus chatbots!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_split.split_text(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_example = '''## Streamlit\n",
    "\n",
    "Pagina inicial\n",
    "## Configurações \n",
    "\n",
    "Existem alguns meios de configurar o streamlit, esses meios são as alterações realizadas pelo script e as alterações realizadas no arquivo de configuração .\n",
    "\n",
    "### Script \n",
    "- **Links importantes**\n",
    "\t- [Execution flow](https://docs.streamlit.io/develop/api-reference/execution-flow)\n",
    "\t- [cache](https://docs.streamlit.io/develop/concepts/architecture/caching#advanced-usage)\n",
    "\t- \n",
    "#### Cache e dados\n",
    "\n",
    "##### st.sess\n",
    "No script podemos alterar  as caracteriticas de formatação da pagina (Esse trecho deve está no script principal)\n",
    "\n",
    "```\n",
    "st.set_page_config(\n",
    "\n",
    "    page_title=\"ISC Company\",\n",
    "\n",
    "    page_icon=r\"./imagens/_ISC Company.png\",\n",
    "\n",
    "    layout=\"wide\",\n",
    "\n",
    "    initial_sidebar_state=\"colapso\" \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "- [st.set_page_config](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config)\n",
    "\t- `page_title` será responsável pelo nome que aparece  na aba \n",
    "\t- `page_icon` será responsável pelo ícone que aparece  na aba \n",
    "\t- `layout` será responsável pelo forma da pagina, nesse caso ela é ampla  \n",
    "\t- `initial_sidebar_state` será responsável pelo estado inicial do sidebar, nesse caso inicia fechado  \n",
    "##### @st.cache_data\n",
    "\n",
    "ddd\n",
    "\n",
    "##### @st.fragment\n",
    "\n",
    "Aparentemente o [@st.fragment](https://docs.streamlit.io/develop/api-reference/execution-flow/st.fragment) funciona isolando o processamento e cache de uma função, fazendo com que não seja executada por inteira e sim apenas aquele fragmento.\n",
    "\n",
    "exemplo: \n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "### Arquivo de configuração \n",
    "\n",
    "O principal arquivo de configuração é o `config.toml` que é um arquivo de formatação. um ponto importante é a localização dos arquivos que deve ser  `%userprofile%/.streamlit/config.toml`\n",
    "\n",
    "A pasta  `.streamlit` ,m conterá todos os arquivos de formatação do streamlit.\n",
    "\n",
    "Voltando ao arquivo  `config.toml`, nele será adotada a estrutura  [TOML](https://toml.io/en/). De modo padrão  teremos o nome da estrutura que iremos configurar (`[server]`) e abaixo as definições (`port = 8501`).  Abaixo temos um exemplo aplicável: \n",
    "\n",
    "```\n",
    "[server]\n",
    "port = 8080\n",
    "\n",
    "[theme]\n",
    "#Cor de destaque para elentos interativos\n",
    "primaryColor = \"#827272\"\n",
    "\n",
    "#Cor de fundo para área principal\n",
    "backgroundColor = \"#eaeaea\"\n",
    "\n",
    "secondaryBackgroundColor = \"#bdb9b9\"\n",
    "\n",
    "[client]\n",
    "toolbarMode = \"minimal\"\n",
    "```\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "header_to_split_on = [\n",
    "    ('#', 'Header 1'),\n",
    "    ('##', 'Header 2'),\n",
    "    ('###', 'Header 3'),\n",
    "    ('####', 'Header 4'),\n",
    "    ('#####', 'Header 5'),\n",
    "    ('######', 'Header 6'),\n",
    "]\n",
    "\n",
    "md_split = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=header_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = md_split.split_text(markdown_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 2': 'Streamlit'}, page_content='Pagina inicial'),\n",
       " Document(metadata={'Header 2': 'Configurações'}, page_content='Existem alguns meios de configurar o streamlit, esses meios são as alterações realizadas pelo script e as alterações realizadas no arquivo de configuração .'),\n",
       " Document(metadata={'Header 2': 'Configurações', 'Header 3': 'Script'}, page_content='- **Links importantes**\\n- [Execution flow](https://docs.streamlit.io/develop/api-reference/execution-flow)\\n- [cache](https://docs.streamlit.io/develop/concepts/architecture/caching#advanced-usage)\\n-'),\n",
       " Document(metadata={'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': 'st.sess'}, page_content='No script podemos alterar  as caracteriticas de formatação da pagina (Esse trecho deve está no script principal)  \\n```\\nst.set_page_config(\\n\\npage_title=\"ISC Company\",\\n\\npage_icon=r\"./imagens/_ISC Company.png\",\\n\\nlayout=\"wide\",\\n\\ninitial_sidebar_state=\"colapso\"\\n)\\n\\n```  \\n- [st.set_page_config](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config)\\n- `page_title` será responsável pelo nome que aparece  na aba\\n- `page_icon` será responsável pelo ícone que aparece  na aba\\n- `layout` será responsável pelo forma da pagina, nesse caso ela é ampla\\n- `initial_sidebar_state` será responsável pelo estado inicial do sidebar, nesse caso inicia fechado'),\n",
       " Document(metadata={'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': '@st.cache_data'}, page_content='ddd'),\n",
       " Document(metadata={'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': '@st.fragment'}, page_content='Aparentemente o [@st.fragment](https://docs.streamlit.io/develop/api-reference/execution-flow/st.fragment) funciona isolando o processamento e cache de uma função, fazendo com que não seja executada por inteira e sim apenas aquele fragmento.  \\nexemplo:  \\n```\\n\\n```'),\n",
       " Document(metadata={'Header 2': 'Configurações', 'Header 3': 'Arquivo de configuração'}, page_content='O principal arquivo de configuração é o `config.toml` que é um arquivo de formatação. um ponto importante é a localização dos arquivos que deve ser `%userprofile%/.streamlit/config.toml`  \\nA pasta `.streamlit` ,m conterá todos os arquivos de formatação do streamlit.  \\nVoltando ao arquivo `config.toml`, nele será adotada a estrutura  [TOML](https://toml.io/en/). De modo padrão  teremos o nome da estrutura que iremos configurar (`[server]`) e abaixo as definições (`port = 8501`).  Abaixo temos um exemplo aplicável:  \\n```\\n[server]\\nport = 8080\\n\\n[theme]\\n#Cor de destaque para elentos interativos\\nprimaryColor = \"#827272\"\\n\\n#Cor de fundo para área principal\\nbackgroundColor = \"#eaeaea\"\\n\\nsecondaryBackgroundColor = \"#bdb9b9\"\\n\\n[client]\\ntoolbarMode = \"minimal\"\\n```')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina inicial\n",
      "{'Header 2': 'Streamlit'}\n",
      " ================== \n",
      "Existem alguns meios de configurar o streamlit, esses meios são as alterações realizadas pelo script e as alterações realizadas no arquivo de configuração .\n",
      "{'Header 2': 'Configurações'}\n",
      " ================== \n",
      "- **Links importantes**\n",
      "- [Execution flow](https://docs.streamlit.io/develop/api-reference/execution-flow)\n",
      "- [cache](https://docs.streamlit.io/develop/concepts/architecture/caching#advanced-usage)\n",
      "-\n",
      "{'Header 2': 'Configurações', 'Header 3': 'Script'}\n",
      " ================== \n",
      "No script podemos alterar  as caracteriticas de formatação da pagina (Esse trecho deve está no script principal)  \n",
      "```\n",
      "st.set_page_config(\n",
      "\n",
      "page_title=\"ISC Company\",\n",
      "\n",
      "page_icon=r\"./imagens/_ISC Company.png\",\n",
      "\n",
      "layout=\"wide\",\n",
      "\n",
      "initial_sidebar_state=\"colapso\"\n",
      ")\n",
      "\n",
      "```  \n",
      "- [st.set_page_config](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config)\n",
      "- `page_title` será responsável pelo nome que aparece  na aba\n",
      "- `page_icon` será responsável pelo ícone que aparece  na aba\n",
      "- `layout` será responsável pelo forma da pagina, nesse caso ela é ampla\n",
      "- `initial_sidebar_state` será responsável pelo estado inicial do sidebar, nesse caso inicia fechado\n",
      "{'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': 'st.sess'}\n",
      " ================== \n",
      "ddd\n",
      "{'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': '@st.cache_data'}\n",
      " ================== \n",
      "Aparentemente o [@st.fragment](https://docs.streamlit.io/develop/api-reference/execution-flow/st.fragment) funciona isolando o processamento e cache de uma função, fazendo com que não seja executada por inteira e sim apenas aquele fragmento.  \n",
      "exemplo:  \n",
      "```\n",
      "\n",
      "```\n",
      "{'Header 2': 'Configurações', 'Header 3': 'Script', 'Header 4': 'Cache e dados', 'Header 5': '@st.fragment'}\n",
      " ================== \n",
      "O principal arquivo de configuração é o `config.toml` que é um arquivo de formatação. um ponto importante é a localização dos arquivos que deve ser `%userprofile%/.streamlit/config.toml`  \n",
      "A pasta `.streamlit` ,m conterá todos os arquivos de formatação do streamlit.  \n",
      "Voltando ao arquivo `config.toml`, nele será adotada a estrutura  [TOML](https://toml.io/en/). De modo padrão  teremos o nome da estrutura que iremos configurar (`[server]`) e abaixo as definições (`port = 8501`).  Abaixo temos um exemplo aplicável:  \n",
      "```\n",
      "[server]\n",
      "port = 8080\n",
      "\n",
      "[theme]\n",
      "#Cor de destaque para elentos interativos\n",
      "primaryColor = \"#827272\"\n",
      "\n",
      "#Cor de fundo para área principal\n",
      "backgroundColor = \"#eaeaea\"\n",
      "\n",
      "secondaryBackgroundColor = \"#bdb9b9\"\n",
      "\n",
      "[client]\n",
      "toolbarMode = \"minimal\"\n",
      "```\n",
      "{'Header 2': 'Configurações', 'Header 3': 'Arquivo de configuração'}\n",
      " ================== \n"
     ]
    }
   ],
   "source": [
    "for doc in split:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(' ================== ')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
